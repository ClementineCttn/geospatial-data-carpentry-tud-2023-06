---
title: "Session 4: GIS Operations"
author: "Cl√©mentine Cottineau"
format: 
  revealjs:
    logo: BKTUD.png
    css: logo.css
    footer: "Data Carpentry for Geospatial Data"
    chalkboard: true
    incremental: true   
    theme: [default, custom.scss]
---


# Objectives:
- Import, select, and visualise OSM vector data
- Learn about basic GIS operation: spatial buffers, centroids, area calculation and vector/raster intersection

# Resources

https://datacarpentry.org/organization-geospatial/03-crs.html

https://saylordotorg.github.io/text_essentials-of-geographic-information-systems/ 

https://www.nfb.ca/film/impossible_map/


```{r}
#| label: setup
#| include: false
# install.packages("devtools")
# devtools::install_github("hadley/emo")


library(dplyr)
library(sf)
library(ggplot2)
library(osmdata)
library(leaflet)
library(emo)


knitr::opts_chunk$set(
  cache = FALSE,
  echo = TRUE,
  message = FALSE, 
  warning = FALSE
  )
```



# Part 1. Import vector data from Open Street Map

## What is Open Street Map?

It is a collaborative project which aims at mapping the world and sharing geospatial data in an open way.

![](fig/OSM1.png){fig-align="center"}

## OSM  `r emo::ji("map")`

Anyone can contribute, by mapping geographical objects their encounter by

- **mapping spatial features** (e.g. buildings or roads), from located device or satellite imagery.
- adding **topical information** on existing map objects (their name, function, capacity, etc.)


## OSM  `r emo::ji("map")`

- This information is then **validated** by other users and eventually added to the common "map" or information system. 
- This ensures that the information is **accessible, open, verified, accurate** and **up-to-date**. cf. HOT: Humanitarian OpenStreetMap Team


## OSM  `r emo::ji("map")`

The geospatial data underlying this interface is made of geometrical objects (i.e. points, lines, polygons) and their associated tags (#building #height, #road #secondary #90kph, etc.).


## How to extract geospatial data from Open Street Map with R?

The first thing to do is to define the area within which you want to retrieve data, aka the *bounding box*. This can be defined easily using a place name and the package `nominatimlite` to access the free Nominatim API provided by OpenStreetMap. 

We are going to look at *Brielle* together, but you can also work with the small cities of *Naarden*, *Geertruidenberg*, *Gorinchem*, *Enkhuizen* or *Dokkum*.


## The Bounding Box `r emo::ji("square")` 

```{r osm-bounding-box}
nominatim_polygon <- nominatimlite::geo_lite_sf(address = "Brielle", points_only = FALSE)
bb <- sf::st_bbox(nominatim_polygon)
bb
```

A Problem with download? Try:

```{r proxy}
assign("has_internet_via_proxy", TRUE, environment(curl::has_internet))
```

## Caution

There might multiple responses from the API query, corresponding to different objects at the same location, or different objects at different locations.

Here, for example we have two options:
![Brielle, Netherlands](fig/Brielle_NL.jpeg){width=30%}
or
![Brielle, New Jersey](fig/Brielle_NJ.jpeg){width=30%}

## Which Brielle?

We should therefore try to be as unambiguous as possible by adding a country code or district name.

```{r osm-bounding-box2}
nominatim_polygon <- nominatimlite::geo_lite_sf(address = "Brielle, NL", points_only = FALSE)
bb <- sf::st_bbox(nominatim_polygon)
bb
```



## Extracting OSM features

A [feature](https://wiki.openstreetmap.org/wiki/Map_features) in the OSM language is a category or tag of a geospatial object. 
**Features** are described by general keys (e.g. "building", "boundary", "landuse", "highway")
Features are decomposed into sub-categories (values) such as "farm", "hotel" or "house" for `buildings`, "motorway", "secondary" and "residential" for `highway`. 
This determines how they are represented on the map.


### Searching the documentation

Let's say we want to download data from OpenStreetMap and we know there is a package for it named `osmdata`, but we don't know which function to use and what arguments are needed. Where should we start?

> Let's check the documentation [online](https://docs.ropensci.org/osmdata/):

### Searching the documentation

It appears that there is a function to extract features, using the Overpass API. This function's name is `opq` (for OverPassQuery) which, in combination with `add_osm_feature`, seems to do the job. However it might not be crystal clear how  to apply it to our case. Let's click on the function name to know more.

On this page we can read about the arguments needed for each function: a bounding box for `opq()` and some `key` and `value` for `add_osm_feature()`. Thanks to the examples provided, we can assume that these keys and values correspond to different levels of tags from the OSM classification. In our case, we will keep it at the first level of classification, with "buildings" as `key`, and no value. We also see from the examples that another function is needed when working with the `sf` package: `osmdata_sf()`. This ensures that the type of object is suited for `sf`. 


## Extracting OSM features

With these tips and examples, we can write our feature extraction function as follows:
```{r osm-feature}
#| eval: false
x <- opq(bbox = bb) %>%
   add_osm_feature(key = 'building')%>%
    osmdata_sf()

```



What is this x object made of?

## Extracting OSM features

```{r osm-feature-preview}
#| eval: false
head(x$osm_polygons)
```

- It is a **table** of all the buildings contained in the bounding box, which gives us their **OSM id**, their **geometry** and a range of **attributes**, such as their name, building material, building date, etc. 
- The **completion** level of this table depends on user contributions and open resources (here for instance: BAG, different in other countries).


## Mapping attributes

Case Study: we are interested in mapping building age in Brielle.
We need to look into specific attributes:

- the **age** of buildings
- with a **subset** of buildings from after 1900
- within the **Brielle** bounding box

## Projections

First, we are going to select the polygons and reproject them with the Amersfoort/RD New projection, suited for maps centered on the Netherlands.

```{r reproject}
#| eval: false
buildings <- x$osm_polygons %>%
  st_transform(.,crs=28992)
```


## Mapping urbanisation in Brielle

Then we create a variable which a threshold at 1900. Every date prior to 1900 will be recoded 1900, so that buildings older than 1900 will be represented with the same shade.

Then we use the `ggplot` function to visualise the buildings by age. The specific function to represent information as a map is `geom_sf()`. The rest works like other graphs and visualisation, with `aes()` for the aesthetics.

## Mapping urbanisation in Brielle

```{r map-age}
#| eval: false

buildings$build_date <- as.numeric(
  if_else(
    as.numeric(buildings$start_date) < 1900, 
          1900, 
          as.numeric(buildings$start_date)
          )
  )

 ggplot(data = buildings) +
   geom_sf(aes(fill = build_date, colour=build_date))  +
   scale_fill_viridis_c(option = "viridis")+
   scale_colour_viridis_c(option = "viridis")

```


## Mapping urbanisation in Brielle

:::: {.columns}

::: {.column width="60%"}
![](fig/rmd-04map-age-1.png){fig-align="center"}
:::

::: {.column width="40%"}
So this reveals the historical centre of [city] and the various extensions.
Anything odd? what? around the centre? Why these limits / isolated points?

:::

::::


## `r emo::ji("alarm")` Challenge: import an interactive basemap layer under the buildings with `Leaflet`

```{r}
#| echo: false
#| cache: false
countdown::countdown(minutes = 20)
```

- Check out the [leaflet package documentation](https://rstudio.github.io/leaflet/)
- Plot a basemap in Leaflet and try different tiles. [Basemap documentation](https://rstudio.github.io/leaflet/basemaps.html)
- Transform the buildings into WGS84 projection and add them to the basemap layer with the `addPolygons` function.
- Have the `fillColor` of these polygons represent the `build_date` variable. [Choropleth documentation](https://rstudio.github.io/leaflet/choropleths.html). Using the example and replace the variable names where needed.


![](fig/leafletBrielle.png){fig-align="center"}

A Problem with download? Try:

```{r proxy_b}
#| eval: false
assign("has_internet_via_proxy", TRUE, environment(curl::has_internet))
```

## Solution

```{r}
#| eval: false
buildings2 <- buildings %>%
  st_transform(.,crs=4326)

leaflet(buildings2) %>%
# addTiles()
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(color = "#444444", weight = 0.1, smoothFactor = 0.5,
  opacity = 0.2, fillOpacity = 0.8,
  fillColor = ~colorQuantile("YlGnBu", -build_date)(-build_date),
  highlightOptions = highlightOptions(color = "white", weight = 2,
    bringToFront = TRUE))

```

## Summary and keypoints
We have seen how OpenStreetMap (OSM) geodata works and how to import, select, and visualise OSM vector data.

In short:

- Use the `osmextract` package
- Select features and attributes among OSM tags
- Use the `leaflet` package to map OSM data


# Part 2. Basic GIS operations with the `sf` package


## Objectives:

- Show how to create spatial **buffers and centroids**
- Demonstrate how to **intersect** vector data
- Present the function to retrieve the **area** of polygons


## the 'sf' package `r emo::ji("box")` 

- `sf` is a package which supports simple features (sf), ["a standardized way to
encode spatial vector data."](https://cran.r-project.org/web/packages/sf/sf.pdf).

- It contains a large set of functions to achieve all the operations on vector spatial data for which you might use traditional GIS software: change the coordinate system, join layers, intersect or unit polygons, create buffers and centroids, etc. 

- cf. the `sf` [cheatsheet](https://raw.githubusercontent.com/rstudio/cheatsheets/main/sf.pdf).

## the 'sf' cheatsheet `r emo::ji("map")` 

![](fig/sf_cheatsheet1.png){fig-align="center"}


## the 'sf' cheatsheet `r emo::ji("map")` 

![](fig/sf_cheatsheet2.png){fig-align="center"}

## Conservation in Brielle, NL `r emo::ji("building")` 

 We are going to go through some of these basics with the case study of Brielle buildings.

Let's focus on really old building and imagine we're in charge of their conservation. We want to know **how much of the city would be affected by a non-construction zone of 100m around pre-1800 buildings**.

Let's select them and see where they are.


## Conservation in Brielle, NL `r emo::ji("building")` 


:::: {.columns}

::: {.column width="50%"}

```{r old-buildings}
#| eval: false
old <- 1800 

summary(buildings$start_date)
buildings$start_date <- 
  as.numeric(as.character(
    buildings$start_date
    ))

old_buildings <- buildings %>%
  filter(start_date <= old)

 ggplot(data = old_buildings) + 
   geom_sf(colour="red")
 
```


:::

::: {.column width="50%"}

![](fig/rmd-04conservation-1.png){fig-align="center"}
:::

::::


## Basic GIS operations

As conservationists, we want to create a zone around historical buildings where building regulation will have special restrictions to preserve historical buildings. 

## Buffer 

Let's say this zone should be 100 meters. In GIS terms, we want to create a buffer around polygons. 
The corresponding function `sf` is `st_buffer`, with 2 arguments:

- "x": the polygons around which to create buffers
- "dist": the radius of the buffer.


```{r buffers}
#| eval: false
 distance <- 100 # in meters 
 
buffer_old_buildings <- 
  st_buffer(x = old_buildings, dist = distance)
 
```


## Buffer 


```{r buffers2}
#| eval: false
 ggplot(data = buffer_old_buildings) + geom_sf()
```

![](fig/rmd-04buffers-1.png){fig-align="center"}

## Union

Now, we have a lot of overlapping buffers. 
We would rather create a **unique** conservation zone rather than overlapping ones in that case. 
So we have to fuse (or dissolve) the overlapping buffers into one polygon. This operation is called **union** in `sf` and the corresponding function is `st_union`.

```{r union}
#| eval: false
 single_old_buffer <- st_union(buffer_old_buildings) %>%
   st_cast(to = "POLYGON") %>%
  st_as_sf() 

single_old_buffer<- single_old_buffer %>%
  mutate("ID"=as.factor(1:nrow(single_old_buffer))) %>%
  st_transform(.,crs=28992) 
```

We also use `st_cast()` to explicit the type of the resulting object (*POLYGON* instead of the default *MULTIPOLYGON*), `st_as_sf()` to transform the polygon into an `sf` object.


## Centroids

For the sake of visualisation speed, we would like to represent buildings by a single point (for instance: their geometric centre) rather than their actual footprint. 

This operation means defining their centroid and the corresponding function is `st_centroid`.

```{r centroids}
#| eval: false
sf::sf_use_s2(FALSE)
centroids_old <- st_centroid(old_buildings) %>%
  st_transform(.,crs=28992)  

ggplot() + 
    geom_sf(data = single_old_buffer, aes(fill=ID)) +
    geom_sf(data = centroids_old)
```


## Centroids

![](fig/rmd-04centroids-1.png){fig-align="center" height=100%}

## Intersection

:::: {.columns}

::: {.column width="50%"}

Now what we would like to distinguish conservation areas based on the number of historic buildings they contain. In GIS terms, we would like to know how many centroids each fused buffer polygon contains. This operation means intersecting the layer of polygons with the layer of points and the corresponding function is `st_intersection`.

:::

::: {.column width="50%"}

```{r intersection}
#| eval: false
 centroids_buffers <- 
  st_intersection(centroids_old,single_old_buffer) %>%
   mutate(n=1)

 centroid_by_buffer <- centroids_buffers %>%
   group_by(ID) %>%
   summarise(n = sum(n))
 single_buffer <- single_old_buffer %>%
   mutate(n_buildings = centroid_by_buffer$n)

  ggplot() + 
   geom_sf(data = single_buffer, 
           aes(fill=n_buildings)) +
   scale_fill_viridis_c(alpha = 0.8,
                        begin = 0.6,
                        end = 1,
                        direction = -1,
                        option = "B")
```

::: 

::::


## Final Output


:::: {.columns}

::: {.column width="50%"}
Let's map this layer over the initial map of individual buildings.

```{r visu-1800}
#| eval: false

ggplot() + 
   geom_sf(data = buildings) +
   geom_sf(data = single_buffer, aes(fill=n_buildings), colour = NA) +
   scale_fill_viridis_c(alpha = 0.6,
                        begin = 0.6,
                        end = 1,
                        direction = -1,
                        option = "B") 

```

:::

::: {.column width="50%"}

![](fig/rmd-04visu-1800-1.png){fig-align="center"}
:::

::::



 

## `r emo::ji("alarm")`Challenge: Conservation rules have changed! 

The historical threshold now applies to all pre-war buildings, but the distance to these building is reduced to 10m. Can you map the number of all buildings per 10m fused buffer?

```{r}
#| echo: false
#| cache: false
countdown::countdown(minutes = 20)
```

Represent visually how many buildings are contained in each of the new buffers

## Solution (one of them)

```{r intersection_viz}
#| eval: false
 old <- 1939 
 distance <- 10
 #select
 old_buildings <- buildings %>%
   filter(start_date <= old)
 #buffer
 buffer_old_buildings <- st_buffer(old_buildings, dist = distance)
  #union
 single_old_buffer <- st_union(buffer_old_buildings) %>%
   st_cast(to = "POLYGON") %>%
   st_as_sf()  
 
 single_old_buffer <- single_old_buffer %>%
   mutate("ID"=1:nrow(single_old_buffer))  %>%
   st_transform(single_old_buffer,crs=4326) 
 #centroids
 centroids_old <- st_centroid(old_buildings) %>%
   st_transform(.,crs=4326)  
  #intersection
  centroids_buffers <- st_intersection(centroids_old,single_old_buffer) %>%
   mutate(n=1)
 centroid_by_buffer <- centroids_buffers %>% 
   group_by(ID) %>%
   summarise(
   n = sum(n)
   )
 single_buffer <- single_old_buffer %>% 
   mutate(n_buildings = centroid_by_buffer$n)
  ggplot() + 
   geom_sf(data = buildings) +
   geom_sf(data = single_buffer, aes(fill=n_buildings), colour = NA) +
   scale_fill_viridis_c(alpha = 0.6,
                        begin = 0.6,
                        end = 1,
                        direction = -1,
                        option = "B") 
```

## Problem


:::: {.columns}

::: {.column width="30%"}
*there are many pre-war buildings and the buffers are large so the number of old buildings is not very meaningful. Let's compute the density of old buildings per buffer zone.*
::: 
::: {.column width="70%"}
![](fig/rmd-04prewar-replication-1.png){fig-align="center" }
::: 
::::


## `r emo::ji("alarm")` Challenge: visualise the density of old buildings

```{r}
#| echo: false
#| cache: false
countdown::countdown(minutes = 20)
```

Let's compute the **density** of old buildings per buffer zone (= number of buildings / area of buffer). 

## Solution

:::: {.columns}

::: {.column width="50%"}
Let's map this layer over the initial map of individual buildings.
```{r area}
#| eval: false

single_buffer$area <- st_area(single_buffer, )  %>% units::set_units(., km^2)

single_buffer$old_buildings_per_km2 <- as.numeric(single_buffer$n_buildings / single_buffer$area)

 ggplot() + 
   geom_sf(data = buildings) +
   geom_sf(data = single_buffer, aes(fill=old_buildings_per_km2), colour = NA) +
   scale_fill_viridis_c(alpha = 0.6,
                        begin = 0.6,
                        end = 1,
                        direction = -1,
                        option = "B") 
 
```

:::

::: {.column width="50%"}
![](fig/rmd-04area-1.png){fig-align="center"}

:::

::::









## Summary and keypoints

We have seen how to create spatial buffers and centroids, how to intersect vector data and how retrieve the area of polygons.

In short:

- Use the `sf` package to treat geospatial data
- Use the `st_*` functions for basic GIS operations
- Use the `ggplot` package to map the results



## `r emo::ji("rabbit")`The end... wait!
![](fig/Thats_all_folks.svg.png){fig-align="center"}

## `r emo::ji("talk")` A few words of caution

We have taught you to think, type, try, test, read the documentation.
This is not only the old fashion way, but the foundation.

When you encounter a bug, a challenge, a question that we have not covered, you could always make use of:

- StackOverflow
- chatGPT
- `< include name of future AI here >`

But be careful to keep it as a help, tool and support whose quality you can still assess. They can provide fixes that you do not understand, answers that don't make sense, and even wrong answers! So build yourself some foundations before you get into them.



## What's next?

- Workshop material and links to other resources will be shared via email
- [R Caf√©](https://delft-rcafe.github.io/home/Index.html) - Join the next session on June 20 (3pm @BK) dedicated to our workshop participants
- Join the [Rbanism Scalable GIS challenge](https://github.com/Rbanism/scalegis-challenge) - deadline June 22
- Join the Rbanism community launch on June 8, 3:30pm-7pm, @BK-Room K then Bouwpub
- Join the Lunch Discussion [Time Travelling in Geo-spatial Data](https://www.eventbrite.com/e/lunch-discussion-time-travelling-in-geo-spatial-data-tickets-643560676307?aff=oddtdtcreator) organised by the OSCD
- [DCC](https://www.tudelft.nl/index.php?id=67120&L=1/) and the [TU Delft Library](https://www.tudelft.nl/en/library/research-data-management/r/training-events/training-for-researchers) - They are there to help

:::: {.columns}

:::{.column width=45%}
- Give us feedback! ![](post-workshop-survey.png){.absolute top=340 left=240 width=200}
:::

:::{.column}
- Drinks! Join Rbanism: ![](rbanism-membership.png){.absolute top=340 left=760 width=200}
:::

::::
